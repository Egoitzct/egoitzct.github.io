[
  {
    "objectID": "tidytuesday/refugees/index.html",
    "href": "tidytuesday/refugees/index.html",
    "title": "Refugiados",
    "section": "",
    "text": "Para el TidyTuesday de la semana del 22 de agosto, el tema es sobre refugiados. Después de leer la descripción que podemos encontrar en la página de github, he decidido hacer un gráfico en el que se incluyan los diez países que más refugiados han recibido.\nCómo siempre, el primer paso es cargar el dataset y los paquetes que usaremos para hacer el gráfico (qué, además de un gráfico estático, también usaremos plotly para añadir un poco de interacción).\n\npopulation &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-22/population.csv')\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(ggrepel)\nlibrary(scales)\nlibrary(plotly)\n\nDespúes de cargar los datos, hay que observarlos y limpiarlos, de forma que todos los datos resultantes sean adecuados para hacer el gráfico.\n\nglimpse(population)\n\nRows: 64,809\nColumns: 16\n$ year              &lt;dbl&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010…\n$ coo_name          &lt;chr&gt; \"Afghanistan\", \"Iran (Islamic Rep. of)\", \"Iraq\", \"Pa…\n$ coo               &lt;chr&gt; \"AFG\", \"IRN\", \"IRQ\", \"PAK\", \"ARE\", \"CHI\", \"GAZ\", \"IR…\n$ coo_iso           &lt;chr&gt; \"AFG\", \"IRN\", \"IRQ\", \"PAK\", \"EGY\", \"CHN\", \"PSE\", \"IR…\n$ coa_name          &lt;chr&gt; \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghan…\n$ coa               &lt;chr&gt; \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"ALB\", \"ALB\", \"ALB\", \"AL…\n$ coa_iso           &lt;chr&gt; \"AFG\", \"AFG\", \"AFG\", \"AFG\", \"ALB\", \"ALB\", \"ALB\", \"AL…\n$ refugees          &lt;dbl&gt; 0, 30, 6, 6398, 5, 6, 5, 5, 49, 5, 5, 0, 0, 6, 6, 66…\n$ asylum_seekers    &lt;dbl&gt; 0, 21, 0, 9, 0, 0, 0, 0, 20, 0, 0, 5, 10, 92, 5, 26,…\n$ returned_refugees &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ idps              &lt;dbl&gt; 351907, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ returned_idps     &lt;dbl&gt; 3366, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ stateless         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ ooc               &lt;dbl&gt; 838250, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ oip               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ hst               &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n\ndata &lt;- population |&gt; \n  filter(refugees &gt;= 100) |&gt; \n  select(year, coo_name, coo_iso, coa_name, coa_iso, refugees, asylum_seekers) |&gt; \n  group_by(coa_iso)\n\ndata &lt;- data |&gt; \n  select(year, coa_name, coa_iso, refugees, asylum_seekers) |&gt; \n  group_by(coa_iso)\n\ndata_plot &lt;- data |&gt;\n  group_by(coa_name) |&gt; \n  summarise(refugees_sum = sum(refugees),\n            asylum_sum = sum(asylum_seekers)) |&gt; \n  ungroup()\n\ndata_plot &lt;- data_plot |&gt; \n  filter(refugees_sum &gt;= 10000 & asylum_sum &gt;= 10000)\n\ndata_plot_1 &lt;- data_plot |&gt; \n  filter(refugees_sum &gt;= 7000000)\n\ndata_plot_2 &lt;- data_plot |&gt; \n  filter(refugees_sum &lt; 7000000) |&gt; \n  adorn_totals(\"row\") |&gt; \n  filter(coa_name == \"Total\")\n\ndata_plot_2$coa_name[1] &lt;- \"Others\"\n\ndata_plot_1 &lt;- data_plot_1 |&gt; \n  arrange(refugees_sum)\n\ndata_plot &lt;- rbind(data_plot_1, data_plot_2)\n\nDespués de tener los datos tal y como los necesitamos, es hora de hacer ambos gráficos (estático e interactivo.\n\nplot &lt;- data_plot_1 |&gt; \n  mutate(coa_name=factor(coa_name, levels=coa_name)) |&gt; \n  ggplot(aes(x = coa_name, y = refugees_sum)) +\n  geom_segment(aes(xend=coa_name, yend=0)) +\n  geom_point(size = 4, color = \"#0FDEE8\") +\n  coord_flip() +\n  xlab(\"\") +\n  ylab(\"Total number of refugees (World`s first 10 countries)\") +\n  theme_bw() +\n  geom_label_repel(aes(x = coa_name, label = refugees_sum)) +\n  scale_y_continuous(trans = log2_trans(),\n                     breaks = trans_breaks(\"log2\", function(x) 2^x),\n                     labels = label_number(scale_cut = cut_long_scale()))\n\ninteractive_plot &lt;- data_plot_1 |&gt; \n  mutate(coa_name=factor(coa_name, levels=coa_name)) |&gt; \n  ggplot(aes(x = coa_name, y = refugees_sum)) +\n  geom_segment(aes(xend=coa_name, yend=0)) +\n  geom_point(size = 4, color = \"#FF7E0F\") +\n  coord_flip() +\n  xlab(\"\") +\n  ylab(\"Total number of refugees (World`s first 10 countries)\") +\n  theme_bw() +\n  scale_y_continuous(trans = log2_trans(),\n                     breaks = trans_breaks(\"log2\", function(x) 2^x),\n                     labels = label_number(scale_cut = cut_long_scale()))\n\nplot\nggplotly(interactive_plot)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "tidytuesday/index.html",
    "href": "tidytuesday/index.html",
    "title": "TidyTuesday",
    "section": "",
    "text": "USA’s Etymology\n\n\n\n\n\n\n\n2023\n\n\nShiny App\n\n\nMap\n\n\n\n\nShiny app developed for the TidyTuesday of 01/08/2023\n\n\n\n\n\n\nSep 10, 2023\n\n\nEgoitz Carral\n\n\n\n\n\n\n  \n\n\n\n\nUSA’s Union Members\n\n\n\n\n\n\n\n2023\n\n\nShiny App\n\n\nMap\n\n\n\n\nShiny app developed for the TidyTuesday of 05/09/2023\n\n\n\n\n\n\nSep 8, 2023\n\n\nEgoitz Carral\n\n\n\n\n\n\n  \n\n\n\n\nRefugiados\n\n\n\n\n\n\n\n2023\n\n\nPlot\n\n\nggplot\n\n\nggrepel\n\n\nTidyTuesday\n\n\nPlotly\n\n\n\n\nTidyTuesday del 22 de agosto de 2023\n\n\n\n\n\n\nSep 4, 2023\n\n\nEgoitz Carral\n\n\n\n\n\n\n  \n\n\n\n\nFair use cases in education\n\n\n\n\n\n\n\n2023\n\n\nPlot\n\n\nggplot\n\n\nggrepel\n\n\nTidyTuesday\n\n\n\n\nTidyTuesday august 29, 2023\n\n\n\n\n\n\nSep 3, 2023\n\n\nEgoitz Carral\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "tidytuesday/USA_Union_Members/index.html",
    "href": "tidytuesday/USA_Union_Members/index.html",
    "title": "USA’s Union Members",
    "section": "",
    "text": "For the TidyTuesday of 05/09/2023 (Rfordatascience (2023) and Macpherson & Hirsch (2023)), after looking at the data, I choose to make a Shiny App. First of all, I selected the variables I wanted (the state, p_members, members, sector and year). I started making a two different plots, one for looking the percentage of union members per sector and the other one for looking at the evolution of union members percentage in each state.\nAfter doing that, I use leaflet for making an interactive map. Then, I adpted the plots and map so they became functions created and use them for the final result, the Shiny App.\n\n\n\n\n\n\n\n\n\n Back to topReferences\n\nMacpherson, D. A., & Hirsch, B. T. (2023). Five decades of CPS wages, methods, and union-nonunion wage gaps at Unionstats.com. Industrial Relations: A Journal of Economy and Society, 62(4), 439–452. https://doi.org/10.1111/irel.12330\n\n\nRfordatascience. (2023). Tidytuesday/data/2023/2023-09-05 at master · rfordatascience/tidytuesday. https://github.com/rfordatascience/tidytuesday/tree/master/data/2023/2023-09-05"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Homepage",
    "section": "",
    "text": "USA’s Etymology\n\n\n\n\n\n\n\n2023\n\n\nShiny App\n\n\nMap\n\n\n\n\nShiny app developed for the TidyTuesday of 01/08/2023\n\n\n\n\n\n\nSep 10, 2023\n\n\nEgoitz Carral\n\n\n\n\n\n\n  \n\n\n\n\nUSA’s Union Members\n\n\n\n\n\n\n\n2023\n\n\nShiny App\n\n\nMap\n\n\n\n\nShiny app developed for the TidyTuesday of 05/09/2023\n\n\n\n\n\n\nSep 8, 2023\n\n\nEgoitz Carral\n\n\n\n\n\n\n  \n\n\n\n\nRefugiados\n\n\n\n\n\n\n\n2023\n\n\nPlot\n\n\nggplot\n\n\nggrepel\n\n\nTidyTuesday\n\n\nPlotly\n\n\n\n\nTidyTuesday del 22 de agosto de 2023\n\n\n\n\n\n\nSep 4, 2023\n\n\nEgoitz Carral\n\n\n\n\n\n\n  \n\n\n\n\nFair use cases in education\n\n\n\n\n\n\n\n2023\n\n\nPlot\n\n\nggplot\n\n\nggrepel\n\n\nTidyTuesday\n\n\n\n\nTidyTuesday august 29, 2023\n\n\n\n\n\n\nSep 3, 2023\n\n\nEgoitz Carral\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "No matching items\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog\n\n\n Back to top"
  },
  {
    "objectID": "tidytuesday/USA_Etymology/index.html",
    "href": "tidytuesday/USA_Etymology/index.html",
    "title": "USA’s Etymology",
    "section": "",
    "text": "For the TidyTuesday of the first of august (Rfordatascience (2023)), I decided to create a map with Leaflet and Shiny. Using both packages, the user can click on a State and get the etymology of the State’s name.\n\n\n\n\n\n\n\n\n\n Back to topReferences\n\nRfordatascience. (2023). TidyTuesday 2023-08-01 · rfordatascience/tidytuesday. https://github.com/rfordatascience/tidytuesday/tree/master/data/2023/2023-08-01"
  },
  {
    "objectID": "tidytuesday/fair_use_cases_in_education/index.html",
    "href": "tidytuesday/fair_use_cases_in_education/index.html",
    "title": "Fair use cases in education",
    "section": "",
    "text": "For this weeks TidyTuesday (Rfordatascience, 2023), there are two datasets, both about fair use cases in USA. Like in every other TidyTuesday, the first step is to download the datasets and load the packages.\n\nfair_use_cases &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-29/fair_use_cases.csv')\nfair_use_findings &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-29/fair_use_findings.csv')\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(ggrepel)\n\nThe step after loading the data is to have a look a it and select the variables that we are going to use for the final plot. This time, I’m going to choose the education related cases.\n\ngt(head(fair_use_cases))\n\n\n\n\n\n  \n    \n    \n      case\n      year\n      court\n      jurisdiction\n      categories\n      outcome\n      fair_use_found\n    \n  \n  \n    De Fontbrune v. Wofsy, 39 F.4th 1214 (9th Cir. 2022)\n2022\n9th Circuit\n9th Circuit\nEducation/Scholarship/Research; Photograph\nFair use not found\nFALSE\n    Sedlik v. Von Drachenberg, No. CV 21-1102 (C.D. Cal. May 31, 2022)\n2022\nC.D. Cal.\n9th Circuit\nPainting/Drawing/Graphic; Photograph\nPreliminary finding; Fair use not found\nFALSE\n    Sketchworks Indus. Strength Comedy, Inc. v. Jacobs, No. 19-CV-7470-LTS-VF (S.D.N.Y. May 12, 2022)\n2022\nS.D.N.Y.\n2nd Circuit\nFilm/Audiovisual; Music; Parody/Satire; Review/Commentary\nFair use found\nTRUE\n    Am. Soc'y for Testing & Materials v. Public.Resource.Org, Inc., No. 13-cv-1215 (D.D.C. Mar. 31, 2022)\n2022\nD.D.C.\nDistrict of Columbia Circuit\nEducation/Scholarship/Research; Textual Work; Used in government proceeding\nMixed Result\nFALSE\n    Yang v. Mic Network Inc., Nos. 20-4097-cv, 20-4201-cv (2d Cir. Mar. 29, 2022)\n2022\n2d Circuit\n2nd Circuit\nNews reporting; Photography\nFair use found\nTRUE\n    Viacom Int’l v. Pixi Universal, Civ. Action No H-21-2612 (S.D. Tex. Mar. 25, 2022)\n2022\nS.D. Tex.\n5th Circuit\nPainting/Drawing/Graphic; Parody/Satire\nFair use not found\nFALSE\n  \n  \n  \n\n\n\ngt(head(fair_use_findings, n = 1L))\n\n\n\n\n\n  \n    \n    \n      title\n      case_number\n      year\n      court\n      key_facts\n      issue\n      holding\n      tags\n      outcome\n    \n  \n  \n    De Fontbrune v. Wofsy\n39 F.4th 1214 (9th Cir. 2022)\n2022\nUnited States Court of Appeals for the Ninth Circuit\nPlaintiffs own the rights to a catalogue comprised of 16,000 photographs of Pablo Picasso’s work, which was originally compiled by Picasso’s friend in 1932 (the “Zervos Catalogue”). In 1995, after obtaining permission from Picasso’s estate to publish a work illustrating and describing works by Picasso, Defendants Alan Wofsy and his company Alan Wofsy & Associates began publishing The Picasso Project—–a series of volumes reproducing images of Picasso’s work, including 1,492 photographs from the Zervos Catalogue. Plaintiffs sued for copyright infringement. A French court held the photographs were protected by copyright because they “added creative features through deliberate choices of lighting, the lens, filters, [and] framing or angle of view.” In 2001, Plaintiffs obtained a judgment in France that subjected Defendants to damages for any further acts of infringement. In 2012, after discovering copies of The Picasso Project in a French bookstore, Plaintiffs enforced their judgment in France and were awarded €2 million. Plaintiffs sought recognition of the judgment in the U.S. courts. The district court granted summary judgment for Defendants, determining that the French judgment was “repugnant to U.S. public policy protecting free expression” because it failed to provide a fair use defense. Plaintiffs appealed; and Defendants cross-appealed on other defenses.\nWhether reproduction of photographs documenting artwork in a reference book that was sold commercially is a fair use.\nThe panel held that the first factor, the purpose and character of the use, weighed against fair use because Defendants conceded that The Picasso Project was a commercial venture and the use at issue—reproduction of the photographs in a book illustrating Picasso’s works—was not transformative. Specifically, the court noted that Defendants’ use “did not serve an ‘entirely different function’ than the originals,” but had overlapping purposes, and the insertion of informative captions did not “necessarily” transform the works. The second factor, the nature of the copyrighted work, did not favor fair use because, although the works were published and documentary in nature, the French court had concluded that the photographs exhibited creative elements. The court determined that the third factor, the amount and substantiality of the work used, weighed against fair use because Defendants failed to demonstrate that “copying the entirety of each photograph was necessary.” The fourth factor, the effect of the use upon the potential market for or value of the copyrighted work, also weighed against fair use because there is a presumption of market harm when the use is commercial and non-transformative. Although Defendants presented evidence that auction prices for the Zervos Catalogue increased while The Picasso Project was on the market, Defendants had not provided evidence that “widespread appropriation” of the works would not harm the market for the photographs. Weighing all the factors, the court had “serious doubts” that fair use would protect Defendants’ use, and, accordingly, granted summary judgment to Plaintiffs on the public policy defense.\nEducation/Scholarship/Research; Photograph\nFair use not found\n  \n  \n  \n\n\n\ncases &lt;- fair_use_cases %&gt;% \n  filter(outcome == \"Fair use found\" | outcome == \"Fair use not found\") %&gt;% \n  select(year, categories, fair_use_found) %&gt;% \n  mutate(\n    education = case_when(\n      stringr::str_detect(categories, \"Education\") ~ \"education_related\",\n      TRUE ~ \"Non_education_related\"\n    )\n  ) %&gt;% \n  filter(education == \"education_related\") %&gt;% \n  select(year, fair_use_found) %&gt;% \n  group_by(year, fair_use_found) %&gt;% \n  summarise(n = n()) %&gt;% \n  ungroup() %&gt;% \n  filter(year &gt;= 1950)\n\nAnd, after creating a new dataset that we are going to use for the plot, is time to create it.\n\nposition &lt;- c()\n\nposition &lt;- ifelse(cases$fair_use_found == TRUE, append(position, 1), append(position, -1))\n\ncases_plot &lt;- cases %&gt;% \n  mutate(\n    position = position\n  )\n\nredondear_decada &lt;- function(x) {\n  return(x - x %% 10)\n}\n\ncases_plot &lt;- cases_plot %&gt;% \n  mutate(\n    year_decade = redondear_decada(year)\n  )\n\ncases_plot_found &lt;- cases_plot[cases_plot$fair_use_found == TRUE, ]\ncases_plot_not &lt;- cases_plot[cases_plot$fair_use_found != TRUE, ]\n\nposition_plot_found &lt;- cases_plot_found %&gt;% \n  group_by(year_decade) %&gt;% \n  summarise(position_sum = sum(position))\n\nposition_plot_not &lt;-cases_plot_not %&gt;% \n  group_by(year_decade) %&gt;% \n  summarise(position_sum = sum(position))\n\nposition_plot &lt;- merge(position_plot_found, position_plot_not, by = \"year_decade\", all = TRUE)\n\nggplot(position_plot, aes(x = year_decade)) +\n  theme_classic() +\n  geom_area(aes(x = year_decade, y = position_sum.x), fill=\"#79DD79\", alpha=0.7) +\n  geom_line(aes(x = year_decade, y = position_sum.x), color=\"#2FB92F\") +\n  geom_point(aes(x = year_decade, y = position_sum.x), color=\"#2FB92F\", size=1.5) +\n  geom_hline(yintercept=0, color=\"black\", linewidth=0.3)+\n  geom_area(aes(x = year_decade, y = position_sum.y), fill=\"#E73A3A\", alpha=0.7) +\n  geom_line(data=position_plot[!is.na(position_plot$position_sum.y),], aes(x = year_decade, y = position_sum.y), color=\"#C81717\") +\n  geom_point(aes(x = year_decade, y = position_sum.y), color=\"#C81717\", size=1.5) +\n  theme(axis.line.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.title.x=element_blank(),\n        axis.title.y=element_blank(),\n        axis.ticks.y=element_blank(),\n        axis.text.x =element_blank(),\n        axis.ticks.x =element_blank(),\n        axis.line.x =element_blank(),\n        legend.position = \"bottom\"\n  ) +\n  geom_text(aes(x=year_decade,y=-0.5,label=year_decade, fontface=\"bold\"),size=3, color='black') +\n  geom_point(aes(x=year_decade, y=0), size=1) +\n  geom_segment(aes(x=year_decade, y=position_sum.x, yend=0.15, xend=year_decade), color=\"#2FB92F\", linetype=\"dashed\") +\n  geom_segment(aes(x=year_decade, y=position_sum.y, yend=0.15, xend=year_decade), color=\"#C81717\", linetype=\"dashed\") +\n  geom_label_repel(aes(x=year_decade, y=position_sum.x, label=paste(position_sum.x, \"fair use found\")), size = 2, color=\"#79DD79\") +\n  geom_label_repel(aes(x=year_decade, y=position_sum.y, label=paste((-position_sum.y), \"fair use case\\nnot found\")), size = 2, color=\"#FF8C8C\") +\n  ggtitle(\"Fair use cases in education from 1950 to 2020\") +\n  theme(\n    plot.title = element_text(color=\"black\", size=20, face=\"bold\", hjust=0.5, vjust=-0.25)\n  ) \n\n\n\n\n\n\nFinal plot\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to topReferences\n\nRfordatascience. (2023). TidyTuesday 2023-08-09 · rfordatascience/tidytuesday. https://github.com/rfordatascience/tidytuesday/blob/master/data/2023/2023-08-29/readme.md"
  }
]